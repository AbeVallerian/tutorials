{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AlexNet on Tensorflow\n",
    "This time I try to develop AlexNet on Tensorflow. Actually, I never worked on neural networks for Computer Vision before, so I am really excited to learn to develop one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is AlexNet?\n",
    "[AlexNet](https://en.wikipedia.org/wiki/AlexNet) is one of the first architectures for Computer Vision. It was developed by *Alex* Krizhevsky (that's why it is called *AlexNet*), Ilya Sutskever, and Geoffrey Hinton in 2012 to tackle [**ImageNet**](http://www.image-net.org) Image Classification problem.\n",
    "\n",
    "I read about AlexNet from [this post](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html). It states that the AlexNet paper, [*ImageNet Classification with Deep Convolutional\n",
    "Neural Networks*](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), was one of the pioneers (after [LeNet](http://yann.lecun.com/exdb/lenet/) in 1998) in Computer Vision.\n",
    "\n",
    "## AlexNet from Scratch\n",
    "For me, the best way to learn a model is to implement it directly. Therefore, I try to develop the architecture from scratch (not so scratch actually). I try to replicate the architecture in this [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf). The paper doesn't explain the architecture in detail, so I infer some of the required details. Btw, I use Tensorflow 1.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of AlexNet is described in the image below (taken from this [paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)):\n",
    "<img src='alexnet.png'>\n",
    "\n",
    "In the image above, the authors splited the parameters into 2 different GPUs, since the parameters are too much for 1 GPU.\n",
    "\n",
    "Some points to be noted in developing the network:\n",
    "- All layers in AlexNet use relu activation function.\n",
    "- All kernel weights are initialized using **Gaussian distribution** with mean **0** and standard deviation **0.01**.\n",
    "- All bias weights are initialized using constant **0** or **1**. Initialization with constant 1 accelerates the early learning stages. However, I'm not sure why the author didn't use constant 1 initialization in every layer. My best guess is that the author found that the learning was very slow in several layers.\n",
    "\n",
    "### 0. Input Layer\n",
    "I create placeholder for the batch of the image with size of 224x224 with 3 channels (RGB). I also create placeholder for the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_batch: Tensor(\"input_layer/image_batch:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "label_batch: Tensor(\"input_layer/label_batch:0\", shape=(?,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('input_layer'):\n",
    "    image_batch = tf.placeholder(tf.float32, [None,224,224,3],\n",
    "                                 'image_batch')\n",
    "    print 'image_batch:', image_batch\n",
    "    label_batch = tf.placeholder(tf.int32, [None], 'label_batch')\n",
    "    print 'label_batch:', label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolution Layer 1\n",
    "The output from the previous layer is filtered with 96 convolutional kernels with size 11x11x3, strides 4x4, and 'SAME' padding. The result passes through the [*Local Response Normalization*](https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/) (LRN) (with the setup similar to the paper). The idea of LRN is to normalize the kernel from the activation function based on the sum of the adjacent kernels, since the output from relu might be very big. Finally, the result passes *Maxpool* with size 2x2 and stride 1x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: Tensor(\"conv_layer_1/conv1:0\", shape=(?, 56, 56, 96), dtype=float32)\n",
      "lrn1: Tensor(\"conv_layer_1/lrn1:0\", shape=(?, 56, 56, 96), dtype=float32)\n",
      "maxpool1: Tensor(\"conv_layer_1/maxpool1:0\", shape=(?, 55, 55, 96), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_layer_1'):\n",
    "    conv1 = tf.layers.conv2d(inputs=image_batch, filters=96,\n",
    "            kernel_size=[11,11], strides=(4,4), padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            bias_initializer=tf.zeros_initializer(),\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01))\n",
    "    conv1 = tf.identity(conv1, name='conv1') # to rename the tensor\n",
    "    print 'conv1:', conv1\n",
    "    lrn1 = tf.nn.lrn(conv1, depth_radius=5, bias=2, alpha=1e-4,\n",
    "                     beta=0.75, name='lrn1')\n",
    "    print 'lrn1:', lrn1\n",
    "    maxpool1 = tf.layers.max_pooling2d(inputs=lrn1, pool_size=[2,2],\n",
    "                                       strides=(1,1))\n",
    "    maxpool1 = tf.identity(maxpool1, name='maxpool1')\n",
    "    print 'maxpool1:', maxpool1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolution Layer 2\n",
    "Similar to the previous layer, the output from the previous layer is filtered with 256 convolutional kernels with size 5x5x96, strides 2x2, and 'SAME' padding. The biases are initilized with constant 1 to accelerate the early stage of learning (according to the paper). The result passes through the LRN and Maxpool with size 2x2 and stride 1x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2: Tensor(\"conv_layer_2/conv2:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "lrn2: Tensor(\"conv_layer_2/lrn2:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "maxpool2: Tensor(\"conv_layer_2/maxpool2:0\", shape=(?, 27, 27, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_layer_2'):\n",
    "    conv2 = tf.layers.conv2d(inputs=maxpool1, filters=256,\n",
    "            kernel_size=[5,5], strides=(2,2), padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            bias_initializer=tf.ones_initializer(),\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01))\n",
    "    conv2 = tf.identity(conv2, name='conv2')\n",
    "    print 'conv2:', conv2\n",
    "    lrn2 = tf.nn.lrn(conv2, depth_radius=5, bias=2, alpha=1e-4,\n",
    "                     beta=0.75, name='lrn2')\n",
    "    print 'lrn2:', lrn2\n",
    "    maxpool2 = tf.layers.max_pooling2d(inputs=lrn2, pool_size=[2,2],\n",
    "                                       strides=(1,1))\n",
    "    maxpool2 = tf.identity(maxpool2, name='maxpool2')\n",
    "    print 'maxpool2:', maxpool2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convolution Layer 3\n",
    "Only convolutional kernels are applied in this layer. The output from the previous layer is filtered with 384 convolutional kernels with size 3x3x256, strides 2x2, and 'VALID' padding. The biases are initialized with constant 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3: Tensor(\"conv_layer_3/conv3:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_layer_3'):\n",
    "    conv3 = tf.layers.conv2d(inputs=maxpool2, filters=384,\n",
    "            kernel_size=[3,3], strides=(2,2), padding='VALID',\n",
    "            activation=tf.nn.relu,\n",
    "            bias_initializer=tf.zeros_initializer(),\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01))\n",
    "    conv3 = tf.identity(conv3, name='conv3')\n",
    "    print 'conv3:', conv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convolution Layer 4\n",
    "Similar to the previous layer, the output from the previous layer is filtered with 384 convolutional kernels with size 3x3x384, strides 1x1, and 'SAME' padding. The biases are initialized with constant 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4: Tensor(\"conv_layer_4/conv4:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_layer_4'):\n",
    "    conv4 = tf.layers.conv2d(inputs=conv3, filters=384,\n",
    "            kernel_size=[3,3], strides=(1,1), padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            bias_initializer=tf.ones_initializer(),\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01))\n",
    "    conv4 = tf.identity(conv4, name='conv4')\n",
    "    print 'conv4:', conv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convolution Layer 5\n",
    "Similar to the previous layer, the output from the previous layer is filtered with 256 convolutional kernels with size 3x3x384, strides 1x1, and 'SAME' padding. The biases are initialized with constant 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5: Tensor(\"conv_layer_5/conv5:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_layer_5'):\n",
    "    conv5 = tf.layers.conv2d(inputs=conv4, filters=256,\n",
    "            kernel_size=[3,3], strides=(1,1), padding='SAME',\n",
    "            activation=tf.nn.relu,\n",
    "            bias_initializer=tf.ones_initializer(),\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01))\n",
    "    conv5 = tf.identity(conv5, name='conv5')\n",
    "    print 'conv5:', conv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fully Connected Layer 1\n",
    "Now, it's fully connected layer time. The output from the previous convolutional layer has to be reshaped before hand. The number of neurons in this layer is 4096. Moreover, the dropout is applied in the output of this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense1: Tensor(\"fc_layer_1/dense1:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('fc_layer_1'):\n",
    "    conv5 = tf.reshape(conv5, [-1, 13*13*256])\n",
    "    dense1 = tf.layers.dense(inputs=conv5, units=4096,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01),\n",
    "            bias_initializer=tf.zeros_initializer())\n",
    "    dense1 = tf.layers.dropout(inputs=dense1, rate=0.5, training=True)\n",
    "    dense1 = tf.identity(dense1, name='dense1')\n",
    "    print 'dense1:', dense1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Fully Connected Layer 2\n",
    "This layer is similar to the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense2: Tensor(\"fc_layer_2/dense2:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('fc_layer_2'):\n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=4096,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01),\n",
    "            bias_initializer=tf.zeros_initializer())\n",
    "    dense2 = tf.layers.dropout(inputs=dense2, rate=0.5, training=True)\n",
    "    dense2 = tf.identity(dense2, name='dense2')\n",
    "    print 'dense2:', dense2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Softmax Layer\n",
    "This is the final layer. Actually, this layer is similar to the previous layer. The only difference is in the activation function. This layer uses softmax for 1000-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax: Tensor(\"softmax_layer/softmax:0\", shape=(?, 1000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('softmax_layer'):\n",
    "    softmax = tf.layers.dense(inputs=dense2, units=1000,\n",
    "            activation=tf.nn.relu,\n",
    "            kernel_initializer=tf.random_normal_initializer(0, 0.01),\n",
    "            bias_initializer=tf.zeros_initializer())\n",
    "    softmax = tf.identity(softmax, name='softmax')\n",
    "    print 'softmax:', softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, all the parameters are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv_layer_1/conv2d/kernel:0' shape=(11, 11, 3, 96) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_1/conv2d/bias:0' shape=(96,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_2/conv2d/kernel:0' shape=(5, 5, 96, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_2/conv2d/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_3/conv2d/kernel:0' shape=(3, 3, 256, 384) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_3/conv2d/bias:0' shape=(384,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_4/conv2d/kernel:0' shape=(3, 3, 384, 384) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_4/conv2d/bias:0' shape=(384,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_5/conv2d/kernel:0' shape=(3, 3, 384, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'conv_layer_5/conv2d/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc_layer_1/dense/kernel:0' shape=(43264, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'fc_layer_1/dense/bias:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'fc_layer_2/dense/kernel:0' shape=(4096, 4096) dtype=float32_ref>,\n",
       " <tf.Variable 'fc_layer_2/dense/bias:0' shape=(4096,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_layer/dense/kernel:0' shape=(4096, 1000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_layer/dense/bias:0' shape=(1000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Loss Function\n",
    "Since this is classification problem, Cross Entropy is the right choice of loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Tensor(\"loss/sparse_softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=label_batch,\n",
    "                                                  logits=softmax)\n",
    "    print 'loss:', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Training\n",
    "The paper uses *Gradient Descent with momentum* for training with additional weight decay. I don't find the exact optimizer in the Tensorflow. *MomentumOptimizer* is the quite similar, but it doesn't have the weight decay. Hence, I modify all gradients to include the weight decay as follows: *weight_decay x learning_rate x variable*. The paper uses *learning_rate = 0.01*, *momentum = 0.9*, and *weight_decay = 0.0005*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=0.01,\n",
    "                                           momentum=0.9)\n",
    "    grads_vars = optimizer.compute_gradients(loss)\n",
    "    grads_vars = [(grad + 0.0005*0.01*var, var)\n",
    "                  for grad, var in grads_vars]\n",
    "    train_op = optimizer.apply_gradients(grads_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Prediction\n",
    "Predicting the output class is very simple. Just use the argmax to find the most likely class. Moreover, calculating the accuracy is simply using *tf.equal* and *tf.reduce_mean*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('predict'):\n",
    "    prediction = tf.argmax(input=softmax, axis=0, output_type=tf.int32,\n",
    "                           name='prediction')\n",
    "    accuracy = tf.reduce_mean(tf.to_float( \\\n",
    "                tf.equal(prediction, label_batch)), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained AlexNet\n",
    "Honestly, I won't train the network by myself (since I don't have a building full of servers like Google!). Moreover, I didn't find the pretrained AlexNet model in Tensorflow or Keras, but I found an interesting github [repository](https://github.com/guerzh/tf_weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "I'm really happy that I can implement AlexNet myself. I think it's not that hard (although I haven't trained it). This model has many parameters, so the training will be very costly. Pretrained model is prefered.\n",
    "\n",
    "Any feedback are welcomed! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2: merlin18 with tf1.4",
   "language": "python",
   "name": "merlin18tf1.4py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
